# Portfolio Tijme Rijkers

## Learning goal 1

**“I want to learn more about working in the python environment and especially within our group project regarding acquiring data from different social media channels”**

My first learning goal was related to working in and with python and acquiring data with this language from social media platforms. At the beginning of the project we all searched for ways to scrape data from different social media platform. We immediately ran into the difficulty to find such scraping codes because diverse social media platforms stated that scraping data from their platforms is against their policy. We managed to scrape comments using Apify which is a scraping platform which allows you to scrape a maximum amount of comments from social media for free.

This was relatively easy way for obtaining data from X and Facebook in which you only had to fill in some information and thereafter allowed you to download a csv file with all the data. I managed to download a file with comments from Facebook, however, since this was not challenging and did not really aligned with my personal learning goal regarding learning more about working in Python environments I choose to focus on visualising the results from the sentiment analysis by writing scripts in jupyter notebook and did not engage anymore on scraping data using Apify. I took the task on my to visualise all the results of the sentiment analysis.

I managed to create various boxplots showing the overall sentiment of the facebook comments, the sentiment of the different newspapers on twitter, comparing facebook and twitter comments based on sentiment and by making a scatterplot of the overall sentiment trend of Facebook over time. I made those visualisation in python using the packages Matplotlib and Seaborn, the results can be seen  when running the sentiment_visualisation document. which can be found here: [GitHub](https://github.com/tijmerijkers/Smart-Environments-Portfolio/blob/main/Visualisation_Sentiment.ipynb)
When reflecting on this process I really learned a lot in a relatively short time regarding using different packages in Python in order to visualise large sets of data. I had not such experience before in python and visualising data. I now know how to use different packages to visualise data in an easy and clear way and I am able to write a python script that runs correctly with the above mentioned results which is really an improvement compared to what I already was able write in python. Thus I consider learn to work in a python environment as accomplished.

## Learning goal 2

**“To know the concept of sentiment and implement sentiment analysis techniques on a data set”**

My second Learning goal is related to the implementation and understanding of a sentiment analysis to analyse our social media comments in order to know what the overall tone of the comments are to be used in our results. Before this project as already mentioned I had never worked with data from social media. Because of this I had never heard of an sentiment analysis, this was a whole new concept for me. Because I wanted to learn more about this analysis concept I initiated to work on the sentiment analyses part to analyse the dataset of comments we had scraped and cleaned. Together with Lotte and Femke, who also wanted to learn more about sentiment analyses in their learning goals, we searched information about sentiment analysis online and together included all our information in a jupyter notebook to analyse our social media comments with this concept. The jupyter notebook that I worked in can also be found in this  [GitHub](https://github.com/tijmerijkers/Smart-Environments-Portfolio/blob/main/Sentiment_Analysis.ipynb.) page.

In this jupyter notebook we uses NLTK Natural language toolkit and the Roberta sentiment model from Huggingface. We used this model because the process of determining the sentiment can be automated which allows us to analyse large amounts of comments easily. A sentiment analysis allowed us to see what the tone of the different comments were to interpret and analyse human emotions in textual data. With this model we can give every comment the label of positive, negative of neutral. In our case we based this scale on -1 til 1 in which -1 is a very negative tone and 1 an very positive tone. Sentiment analysis is a natural language processing technique. With this technique you can understand how people are talking about a certain subject. This model is developed by Facebook AI and is an extension of the BERT model, the advantage of the Roberta sentiment model is that it is trained on a much larger dataset. The Roberta model not only looks into certain specific words but also in the surrounding context which can change the meaning of a word. This is important in comments where the context of the text is crucial to understand which applies to our project regarding the emotions towards the nitrogen crisis.

I think overall we really managed to make the sentiment analysis work, we had a lot of work with searching the correct sentiment analysis and writing the python codes in the jupyter notebook to analyse our dataset with thousands of comments and solving errors within the script. But with the little knowledge we had before starting with this I think we learned a lot about what this sentiment model does and how to incorporate it within our own project and it gave us some interesting results about the tone of various comments on Facebook posts and beneath newspapers in X. I now know how to perform and apply such a sentiment analysis in python and for what purposes I can use this model.

## Learning goal 3

**“To improve my knowledge on ethical guidelines related to data research”**

My last learning goals related to the ethics of data research was a topic which was relatively new to me. To learn more about ethical guidelines related to data I actively took part in the writing of the two papers on societal and ethical aspects of both data and algorithms. Since I wanted to learn more on this topic I also read all the corresponding papers given in Brightspace and actively searched for papers on google scholar and the online wur library related to ethical and social aspects specifically related to the use of data on social media and using data from social media users and the implications of this. The paper on societal and ethical aspects of data and algorithms I wrote mostly together with Femke and Libra (Tanqunqi). The results of those assignments and the additional papers (in the reference section) that I read can be found in the societal and ethical aspects papers that are provided in this [Github](https://github.com/tijmerijkers/Smart-Environments-Portfolio/blob/main/Societal_and_Ethical_aspects_of_Data_group5.docx) page. Looking back on where I stood in terms of knowledge regarding ethical aspects and data I now know a lot more about the ethical and societal implications regarding using social media data in research and I am more aware of the consequences this can cause to both research and society.

In our specific project that was about the sentiment of the Dutch society on social media platforms regarding the nitrogen crises I learned that social media data can be very valuable to analyse societal trends but that there are also ethical and societal dilemmas such as respecting privacy, getting consent, biases that are in place and potential harm that misuse of data or datasets can have. I for example learned that this research can be prone to all sorts of different biases such as collection and behavioural biases which might influence the representativeness of the study. Furthermore, web scraping activities can raise ethical issues related to the privacy of the users and their right to be forgotten when for example the dataset is misused or not anonymised and informed consent is missing.

There are also moral considerations regarding reproducibility of methods and datasets for example by sharing datasets which sometimes is against official terms of use of the social media platforms and privacy legislations. Despite this, it is an important aspect of research integrity which demands reproducibility and transparency. Therefore researchers must weigh the benefits of using social media datasets against ethical implications and consequences of violating the policies of various social media platforms. They have to take into consideration that using certain datasets involves obtaining consent from users, engage with platform providers or look for alternative sources of data.

## Reflection of the learning process

We had a team that consisted out of 6 people, the most of us had different backgrounds and interests. Also everybody got their own skills and preferences within the project to work on something, for example Libra and Wahdan already had worked with social media data before, Lotte, Femke, Carla and me were new in using social media as a dataset but wanted this subject because we found it interesting and wanted to do something new besides working with environmental data that we did a lot in previous courses and projects. Nobody had done a sentiment analyses before and everybody had their own experience with working in a programming language such as python so everybody was at another efficiency level and speed of working with this to write scripts.

### Struggles

At first we all were a bit struggling with the retrieving data from the social media platforms, especially X (Twitter) was particularly hard to scrape because you had to pay for a lot of data. For a long period we tried to see what the best options were to scrape the comments from any social media platform. Our initial plan was to link the sentiment of different regions with the farmer's density in the Netherlands and see whether there was a trend in sentiment or not however, we immediately ran against problems with retrieving the geo locations from the comments so that was difficult since we had to change our whole project set up and change the research question so this phase was the toughest in terms of searching to get useful and valuable data.

It was also difficult that from week 2 everybody was working on something but you did not know exactly on which parts, which resulted in inefficiency or sometimes that multiple people were working on the same parts and doing things double for example writing the same scripts to get the same results. Because of this we had to manage tasks and assign everybody to a certain tasks and split up or working in smaller groups. I learned that we had to communicate clearly to each other since with all our different backgrounds everybody understood sometimes something different or did not know exactly what was expected from them.

### Boundary crossing competences

However, I think when the project continued this worked really well because we made clear which tasks everybody had to do and what was more or less expected from them.  When I reflect on this process I see how important it is to communicate clearly with each other in the group on expectations and task division to make the project structured and manageable. I think in the end we managed to adapt and worked really well together. Especially because I also learned that we all had to use our own strengths an skills to work on something together with the different learning goals of everybody we could tackle different problems in our project such as helping with writing scripts in python or with the ethical aspects of data science which was for some harder to get than others. In my opinion this interdisciplinary collaboration helped us to deliver good results at the end. I think we managed as a group to really get things done relatively quickly such as cleaning and structuring the data and performing the different analyses because we split tasks up and helped each other when we ran into problems somewhere.

### Project outcomes

Our project outcomes regarding the Dutch sentiment on the nitrogen crises showed that the overall sentiment was slightly negative on both twitter and Facebook and that is was clearly visible especially after events such as new governmental policies or imposed rule that the sentiment of the comments showed a peak or dip immediately after these events. These sentiment trends are in general really useful to see the opinion of the society on for example governmental policies or debatable subjects. However, as mentioned before it also highlights the privacy concerns and biases that should be taken into consideration with social media research.

